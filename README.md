
This project started with the aim to exemplify how homotopy type theory can handle a common practice in informal mathematics without violating its spirit, namely "arguing up to isomorphisms".

A striking example of this practice is described by Kevin Buzzard when he [reports](https://www.icms.org.uk/downloads/bigproof/Buzzard.pdf) on his [formalization of perfectoid spaces](https://leanprover-community.github.io/lean-perfectoid-spaces/) together with Johan Commelin and Patrick Massot: When you iterate localizations of a ring by inverting several elements, you often want to work instead with a one-step localization, by inverting the product of the elements. Mathematicians immediately assert that both localized rings are uniquely isomorphic and use them interchangeably without bothering any longer - for proof checkers, this becomes a much more serious problem. In particular, it is not possible to apply rewrite-tactics as long as there is no actual equality but just isomorphisms. 

Homotopy type theory (HoTT) with its careful analysis of equality and its univalent foundations (UF) is perfectly suited to deal with this situation: Isomorphisms will be equivalent to equalities of localized rings, and standard rewrite tactics apply. To formalize this statement, a trick attributed by Kevin Buzzard to Neil Strickland can deploy its full power: 
> Characterize an object with a universal property by predicates that imply the universal property.

HoTT/UF then not only allows to deduce unique isomorphisms between objects satisfying these predicates but equality.

Instances of this trick are already useful in set theory. But homotopy type theory also clarifies other aspects of sets and redefines categories in a way more consistent with usage by working mathematicians: 
* First of all, and in marked contrast to [mathlib in Lean 3](https://leanprover-community.github.io/mathlib-overview.html), sets in HoTT are types whose derived equality types satisfy a certain property, and are not given as predicates on types. To me, having different types of sets according to the type of their elements sounds more like the concept of a subset. 

* Furthermore, the idea at the very heart of homotopy type theory can be exemplified by discussing the following question: "When are two sets equal?" The classical answer is "if the two sets have the same elements", but that contradicts the paradigm of type theory that every object must have a type, so objects of different type cannot be equal. An answer consistent with type theory is "if there is a bijection between the two sets" - but then there will be lots of different equalities between two given sets, a hallmark of homotopy type theory. The easy half of univalence yields such a bijection from an equality, the difficult half (which is the actual Univalence Axiom) provides you with an equality given a bijection.

* Mathematicians who take a look at HoTT sometimes [dislike univalence](https://xenaproject.wordpress.com/2020/02/09/where-is-the-fashionable-mathematics/) because it seems to produce equalities too easily. But in the case of sets the procedure only works, and works in many different ways, because sets do not give any extra information on their elements. As soon as the sets have extra structure equalities in HoTT need to take into account this extra structure, leading to isomorphisms - that's why all number fields are *not* equal in HoTT.

* A proof of the equivalence of equalities and bijections of sets can be found in [sets/basic.lean](https://github.com/theckl/HoTT-Case-Study/blob/master/src/sets/basic.lean). By the way, this shows in HoTT that the type of sets is not a set: There are too many different bijections between two bijective sets.  

* In HoTT, categories will have *sets* (in the HoTT sense) of homomorphisms between two given objects (so is *small* in non-HoTT terminology), and isomorphisms between objects must be equivalent to identities (see [HoTT-Book,Ch.9.1](https://hott.github.io/book/hott-online-1355-g95ed534.pdf) for further details). One instance where this immediately pays off is the definition of subobjects of a given object in the category: They are defined as isomorphism classes of monomorphisms into the object, but in HoTT you know that these isomorphic monomorphisms are all equal (see [categories/basic.lean](https://github.com/theckl/HoTT-Case-Study/blob/master/src/categories/basic.lean) for a formalisation). 

* Incidentally, the definition of monomorphisms via a universal property (the right cancelling property of homomorphisms factoring through the monomorphism) is an instance of Strickland's trick. Even if the definition of subsets is more effective using predicates, this is due to a particular property of the category of sets, namely the existence of a subobject classifier as in all topoi (see the [entry in nlab](https://ncatlab.org/nlab/show/subobject+classifier) for definitions). 

When formalizing the algebraic hierarchy needed to define and state properties of localisations of rings, and inspired by the [article of Blechschmidt](https://arxiv.org/abs/2111.03685) and a [lecture series of Lafforgue](https://warwick.ac.uk/fac/sci/maths/research/events/events2021-22/toposesasbridges/), the focus of the project changed into an attempt to formalize algebraic geometry using categorical model theory and topoi that allows to cut short many of the tedious proofs involved in the build-up of the theory. The strategy is to prove statements in formal languages with certain *geometric* properties and to use that the corresponding statements in categorical models must also hold. Blechschmidt gives several examples how sheaf-theoretic arguments are translated this way into much easier proofs with an intuitive set-theoretic flavour. But the power of the technique is already shown when deducing the categorical properties of algebraic structures via their definition by formal languages. 

In [sets/theories](https://github.com/theckl/HoTT-Case-Study/blob/master/src/sets/theories.lean) first-order languages and their algebraic and geometric properties as presented in the [first chapter of Caramello's book](https://doi.org/10.1093/oso/9780198758914.003.0003) are completely formalized. The corresponding categorical models are constructed in [categories/structures](https://github.com/theckl/HoTT-Case-Study/blob/master/src/categories/structures.lean) (as yet incomplete).

The formalization of this project started in [Lean 2](https://github.com/leanprover/lean2) using the extensive [HoTT library](https://github.com/leanprover/lean2/blob/master/hott/hott.md) of van Doorn, von Raumer and Buchholtz. Note that the [frozen version of Lean 2](https://github.com/leanprover/lean2) can still be installed and works well in the HoTT mode. Unfortunately, for intrinsic logical reasons this library could only be [ported to Lean 3](https://github.com/gebner/hott3) using some tricks, so for comaprison reasons I stored the Lean 2 files into a separate folder [Lean2-HoTT](https://github.com/theckl/HoTT-Case-Study/blob/master/Lean2-HoTT/).

At the moment, formalisation is done in the [HOTT3 library](https://github.com/gebner/hott3) based on Lean 3. Look in the [overview file](https://github.com/theckl/HoTT-Case-Study/blob/master/src/overview) to see which files compile at the moment, which still have sorries or must be completely revised. Of course, the next step must be to port it to Lean 4. However, before starting this process it may be worth thinking hard on a redesign of HoTT3, possibly including developments from Cubical Type Theory that make the Univalence Axiom and Higher Inductive Types into *computable* theorems and constructions. Theoretically, this is *proven* to work (see the [paper of Cohen, Coquand, Huber and M&#x00F6;rtberg](https://drops.dagstuhl.de/opus/volltexte/2018/8475/pdf/LIPIcs-TYPES-2015-5.pdf) for details), but there is no interpretation of Cubical Type Theory implemented in a Homotopy Type Theory using the Calculus of Inductive Construction, like HoTT3. 

This project wants to spark the working mathematicians' interest in using homotopy type theory in everyday's mathematics. It also provides a first glimpse why homotopy type theory can be instrumental for the next big step(s) in the change from informal to formal mathematics: After the big proofs collecting many small cases like the 4-color theorem, the Thompson-Feit theorem and of course the proof of the Kepler Conjecture, after the formalization of intricate concepts like perfectoid spaces relying on a deep hierarchy of mathematical notions, one of the next steps should be to formalize intricate theorems and, even better, conjectures on which people actually work at the moment. Thomas Hales initiated the [Formal Abstracts project](https://formalabstracts.github.io/) in 2017 along these lines. Developments like the "Liquid Tensor Experiment" or the formalisation of a proof of the Unit Fractions Conjecture before it received a referee report (as reported on the [Xena blog](https://xenaproject.wordpress.com/2023/01/08/lean-2022-round-up/)) point towards even another use of proof checkers in mathematics: as actual proof checkers of brand new results, on the way improving the proofs and their presentation.

A good example for an intricate conjecture could be Bloch's Conjecture, a very deep prediction on the size of certain parameter spaces of points on complex algebraic surfaces from their cohomology groups. Some years ago, Joseph Ayoub [presented a suggestion for a proof](https://www.youtube.com/watch?v=DIZHXXIH25E), but it was rejected after some time because the localization techniques (yes, indeed) used on categories were considered to be too advanced to be trusted. Homotopy type theory might really contribute to this piece of ["fashionable mathematics"](https://xenaproject.wordpress.com/2020/02/09/where-is-the-fashionable-mathematics/).


